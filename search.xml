<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>理解CUDA中的thread,block,grid和warp</title>
      <link href="//posts/85eb5247179b/"/>
      <url>//posts/85eb5247179b/</url>
      
        <content type="html"><![CDATA[<p>之前写在知乎上的，现在放在自己的网站上。(<a href="https://zhuanlan.zhihu.com/p/123170285">https://zhuanlan.zhihu.com/p/123170285</a>)</p><p>本篇文章是从网上一些文章中整理得到的，具体请查看参考文章。<br><img src="https://s2.loli.net/2023/01/06/jUnRtKgBQeuHAsE.jpg" alt="CUDA软件和硬件结构"></p><h1>从硬件上看</h1><ul><li><strong>SP(Streaming Processor)</strong>：流处理器， 是GPU最基本的处理单元，在fermi架构开始被叫做CUDA core。</li><li><strong>SM(Streaming MultiProcessor)</strong>：一个SM由多个CUDA core组成，<strong>每个SM根据GPU架构不同有不同数量的CUDA core</strong>，Pascal架构中一个SM有128个CUDA core。<br>SM还包括特殊运算单元(SFU)，共享内存(shared memory)，寄存器文件(Register File)和调度器(Warp Scheduler)等。register和shared memory是稀缺资源，<strong>这些有限的资源就使每个SM中active warps有非常严格的限制，也就限制了并行能力</strong></li></ul><h1>从软件上看</h1><ul><li><strong>thread</strong>： 一个CUDA的并行程序会被以许多个thread来执行</li><li><strong>block</strong>： 数个thread会被群组成一个block，同一个block中的thread可以同步，也可以通过shared memory进行通信</li><li><strong>grid</strong>：多个block则会再构成grid</li></ul><div align=center><img src="https://s2.loli.net/2023/01/06/SXAqoQsBPLJvVxD.png"/></div><h1>Warp</h1><p>SM采用的SIMT(Single-Instruction, Multiple-Thread，单指令多线程)架构，warp(线程束)是最基本的执行单元，一个warp包含32个并行thread，这些thread<strong>以不同数据资源执行相同的指令</strong>。</p><p>当一个kernel被执行时，grid中的线程块被分配到SM上，<strong>一个线程块的thread只能在一个SM上调度</strong>，SM一般可以调度多个线程块，大量的thread可能被分到不同的SM上。每个thread拥有它自己的程序计数器和状态寄存器，并且用该线程自己的数据执行指令，这就是所谓的Single Instruction Multiple Thread(SIMT)。</p><p>一个CUDA core可以执行一个thread，一个SM的CUDA core会分成几个warp（即CUDA core在SM中分组)，由warp scheduler负责调度。尽管warp中的线程从同一程序地址，但可能具有不同的行为，比如分支结构，因为GPU规定warp中所有线程在同一周期执行相同的指令，warp发散会导致性能下降。<strong>一个SM同时并发的warp是有限的</strong>，因为资源限制，SM要为每个线程块分配共享内存，而也要为每个线程束中的线程分配独立的寄存器，所以SM的配置会影响其所支持的线程块和warp并发数量。</p><p>每个block的warp数量可以由下面的公式计算获得：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>W</mi><mi>a</mi><mi>r</mi><mi>p</mi><mi>P</mi><mi>e</mi><mi>r</mi><mi>B</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mo>=</mo><mi>c</mi><mi>e</mi><mi>i</mi><mi>l</mi><mo fence="false" stretchy="true" minsize="1.2em" maxsize="1.2em">(</mo><mfrac><mrow><mi>T</mi><mi>h</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>P</mi><mi>e</mi><mi>r</mi><mi>B</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi></mrow><mrow><mi>W</mi><mi>a</mi><mi>r</mi><mi>p</mi><mi>S</mi><mi>i</mi><mi>z</mi><mi>e</mi></mrow></mfrac><mo fence="false" stretchy="true" minsize="1.2em" maxsize="1.2em">)</mo></mrow><annotation encoding="application/x-tex">WarpPerBlock=ceil\big(\frac{ThreadPerBlock}{WarpSize}\big)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Wa</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.13889em;">pP</span><span class="mord mathnormal" style="margin-right:0.02778em;">er</span><span class="mord mathnormal" style="margin-right:0.01968em;">Bl</span><span class="mord mathnormal">oc</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2519em;vertical-align:-0.8804em;"></span><span class="mord mathnormal">ce</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">Wa</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.05764em;">pS</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ze</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">h</span><span class="mord mathnormal">re</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.02778em;">er</span><span class="mord mathnormal" style="margin-right:0.01968em;">Bl</span><span class="mord mathnormal">oc</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="delimsizing size1">)</span></span></span></span></span></span></p><p>一个warp中的线程必然在同一个block中，如果block所含线程数目不是warp大小的整数倍，那么多出的那些thread所在的warp中，会剩余一些inactive的thread，也就是说，即使凑不够warp整数倍的thread，硬件也会为warp凑足，只不过那些thread是inactive状态，需要注意的是，即使这部分thread是inactive的，也会消耗SM资源。<strong>由于warp的大小一般为32，所以block所含的thread的大小一般要设置为32的倍数</strong>。</p><h1>thread,block,grid</h1><p>一个grid可以包含多个block，block的组织方式可以是一维的，二维或者三维的。block包含多个thread，这些thread的组织方式也可以是一维，二维或者三维的。<strong>CUDA中每一个线程都有一个唯一的标识ID即threadIdx</strong>，这个ID随着Grid和Block的划分方式的不同而变化，例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 一维的block，一维的thread int tid = threadIdx.x + blockIdx.x * blockDim.x;</span></span><br><span class="line"><span class="type">int</span> tid = threadIdx.x + blockIdx.x * blockDim.x;</span><br></pre></td></tr></table></figure><p>thread，block，gird在不同维度的大小根据算力不同是有限制的：<br><img src="https://s2.loli.net/2023/01/06/vNpjGuqJsRlr2Wn.png" alt=""><br>之前我遇到过CUDA8.0和CUDA10.0在gridDim.y最大size上的问题，可能是因为CUDA8.0仍支持2.x算力,gridDim.y最大size为65535，而之后的CUDA版本比如CUDA10.0已经不在支持，gridDim.y最大size为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>31</mn></msup><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2^{31}-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">31</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>，<strong>所以在不同CUDA版本或在编译时没有指定架构的情况下，可能CUDA版本也会对thread，block，grid在不同维度的大小产生影响</strong>。</p><h1>Reference</h1><ul><li><a href="https://en.wikipedia.org/wiki/CUDA">https://en.wikipedia.org/wiki/CUDA</a></li><li><a href="https://zhuanlan.zhihu.com/p/34587739">https://zhuanlan.zhihu.com/p/34587739</a></li><li><a href="https://www.cnblogs.com/1024incn/p/4541313.html">https://www.cnblogs.com/1024incn/p/4541313.html</a></li><li><a href="https://blog.csdn.net/junparadox/article/details/50540602">https://blog.csdn.net/junparadox/article/details/50540602</a></li><li><a href="https://blog.csdn.net/dcrmg/article/details/54867507?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task">https://blog.csdn.net/dcrmg/article/details/54867507?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task</a></li><li><a href="https://zhuanlan.zhihu.com/p/53763285">https://zhuanlan.zhihu.com/p/53763285</a></li><li><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide">https://docs.nvidia.com/cuda/cuda-c-programming-guide</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> CUDA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
